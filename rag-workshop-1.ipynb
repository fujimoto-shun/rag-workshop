{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3fa8177-c120-4e5e-b0d8-7713b9061a0c",
   "metadata": {},
   "source": [
    "# RAG Workshop #1 è³ªå•ã‚’Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948924c1-cae3-4046-b38d-e367dcf24b2b",
   "metadata": {},
   "source": [
    "\n",
    "## ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™\n",
    "\n",
    "### ä½¿ç”¨ãƒ‡ãƒ¼ã‚¿\n",
    "wikivoyageã«ã‚ã‚‹æ—¥æœ¬ã®è¦³å…‰åœ°ã‚’URLã§ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã™ã‚‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d154ebd6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "916b44a1-ef1b-4cc3-b4ce-0559affc9fc7",
   "metadata": {},
   "source": [
    "### ChromaDB ã¨ã„ã†Vector DBã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f8160-3d18-4668-b1a4-60d110718f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1723ba1-6b0e-4c81-ad98-f89ff60d2463",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=\"./my_chroma_db\")\n",
    "\n",
    "granular_collection = Chroma(\n",
    "    client=client,\n",
    "    collection_name=\"granular\",\n",
    "    embedding_function=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\"),\n",
    ")\n",
    "\n",
    "granular_collection.reset_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a65632b-6508-4d10-8c02-819f0b2acf53",
   "metadata": {},
   "source": [
    "### HTMLSectionSplitterã‚’ä½¿ã£ã¦HTMLã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ—ã—ã€chromadbã®ä¸­ã«INGESTã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0d88ea-1b56-4a03-8db2-c23a293e1491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import HTMLSectionSplitter\n",
    "from langchain_community.document_loaders import AsyncHtmlLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fbb432-b8ef-4c85-a490-434e3e6720da",
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations = [\n",
    "    \"Tokyo\",\n",
    "    \"Hiroshima\",\n",
    "    \"Kanazawa\",\n",
    "    \"Kyoto\",\n",
    "    \"Nagasaki\",\n",
    "    \"Nara\",\n",
    "    \"Osaka\",\n",
    "    \"Sapporo\",\n",
    "    \"Sendai\",\n",
    "]\n",
    "\n",
    "wikivoyage_root_url = \"https://en.wikivoyage.org/wiki\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9393f8-c15e-444f-97dc-ed05b64d138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_urls = [f\"{wikivoyage_root_url}/{d}\" for d in destinations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2246836-ce23-4963-81d2-4051cf34c120",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [(\"h1\", \"Header 1\"), (\"h2\", \"Header 2\")]\n",
    "html_section_splitter = HTMLSectionSplitter(headers_to_split_on=headers_to_split_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf1ebee-a9b9-4102-b208-9a29c9a070db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_docs_into_granular_chunks(docs):\n",
    "    all_chunks = []\n",
    "    for doc in docs:\n",
    "        html_string = doc.page_content\n",
    "        temp_chunks = html_section_splitter.split_text(html_string)\n",
    "        h2_temp_chunks = [\n",
    "            chunk for chunk in temp_chunks if \"Header 2\" in chunk.metadata\n",
    "        ]\n",
    "        all_chunks.extend(h2_temp_chunks)\n",
    "\n",
    "    return all_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9829e9e6-9cfe-4bbc-83ee-af4641346cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for destination_url in destination_urls:\n",
    "    html_loader = AsyncHtmlLoader(destination_url)\n",
    "    docs = html_loader.load()\n",
    "\n",
    "    for doc in docs:\n",
    "        print(doc.metadata)\n",
    "        granular_chunks = split_docs_into_granular_chunks(docs)\n",
    "        granular_collection.add_documents(documents=granular_chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b764315-24d2-48c4-aa74-c97a93459261",
   "metadata": {},
   "source": [
    "## Rewrite-retrieve-readã‚’ä½¿ãŠã†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee81078c",
   "metadata": {},
   "source": [
    "### å¾“æ¥ã®RAGã®å•é¡Œç‚¹\n",
    "- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ãŒä¸æ˜ç­ãªå ´åˆã€é©åˆ‡ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ¤œç´¢ã§ããªã„ã“ã¨ãŒã‚ã‚‹ã€‚\n",
    "- ãã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ç”Ÿã¾ã‚ŒãŸã®ãŒ Rewrite-Retrieve-Readã¨ã„ã†æ‰‹æ³•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d9495-4e11-4cbb-8e3f-07d4d8c30a59",
   "metadata": {},
   "source": [
    "### ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ¤œç´¢ã—ã¦ã¿ã‚‹\n",
    "\n",
    "-  Scoreã¯é«˜ã„ã»ã©æ¤œç´¢æ¡ä»¶ã«ã‚ˆã‚Šè¿‘ã„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b024738-b46d-4709-91f8-50e941e68276",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"åŒ—æµ·é“ã§æ¥½ã—ã‚ã‚‹ã“ã¨ã¯ï¼Ÿ\"\n",
    "improved_results = granular_collection.similarity_search_with_score(\n",
    "    query=user_question, k=4\n",
    ")\n",
    "for i, (doc, score) in enumerate(improved_results):\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"ğŸ¯ Result {i + 1}:\")\n",
    "    print(f\"ğŸ’« Score: {score:.2f}\")\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a637f6a-117f-4e93-9c9b-84d361369dde",
   "metadata": {},
   "source": [
    "çµæœï¼š è³ªå•ãŒæ‚ªã„ã¨å¼•ã£å¼µã£ã¦ã“ã‚‰ã‚Œã‚‹Chunkã‚‚ã²ã©ã„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4b329e-739c-44e9-a5f9-1567d9e79fcd",
   "metadata": {},
   "source": [
    "### ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’æ›¸ãæ›ãˆãŸã‚‰ã©ã†ãªã‚‹ã‹â€¦"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dbfa99-ec8a-4775-a4a7-33502ee21533",
   "metadata": {},
   "source": [
    "### è³ªå•ã‚’æ›¸ãæ›ãˆã¦ãã‚Œã‚‹ Rewriter chain ã‚’ setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4fc6b2-eb69-48e3-9d15-b4e5ff6a5096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3034a15b-cec3-433e-856e-dbfdcfa8eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"gemma3:4b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd69623",
   "metadata": {},
   "source": [
    "â€¼ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã¯æ—¥æœ¬èªã€æœ€çµ‚ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã¯æ—¥æœ¬ã€å†…éƒ¨ã¯è‹±èªãŒæœ›ã¾ã—ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e60da8d-6566-4d5a-a7a8-bbabc9fcb050",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewriter_prompt_template = \"\"\"\n",
    "Generate search query for the Chroma DB vector store from a user question, allowing for a more accurate response through semantic search.\n",
    "Just return the revised Chroma DB query, with quotes around it. \n",
    "\n",
    "User question: {user_question}\n",
    "Revised Chroma DB query:\n",
    "\"\"\"\n",
    "\n",
    "rewriter_prompt = ChatPromptTemplate.from_template(rewriter_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3037753f-2919-4a08-a4dd-e1e4157d5429",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewriter_chain = rewriter_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5342f6fb-ee59-4b1a-a8f9-4f27a34f5039",
   "metadata": {},
   "source": [
    "\n",
    "### æ›¸ãç›´ã•ã‚ŒãŸè³ªå•ã§æƒ…å ±ã‚’chromadbã‹ã‚‰å›åã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329c68fc-28ea-4ea0-8a68-d051880191ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = rewriter_chain.invoke({\"user_question\": user_question})\n",
    "print(search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef23e323-16dd-49bd-923f-2476687bf71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_results = granular_collection.similarity_search_with_score(\n",
    "    query=user_question, k=4\n",
    ")\n",
    "for i, (doc, score) in enumerate(improved_results):\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"ğŸ¯ Result {i + 1}:\")\n",
    "    print(f\"ğŸ’« Score: {score:.2f}\")\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5482c37-a227-4a99-ae35-c8adec9183dc",
   "metadata": {},
   "source": [
    "###  RAG Chain ã‚’ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1102bfee-cabb-45dc-88e4-198c394489e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41036bbe-1043-41a1-af38-e1db6aa7532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = granular_collection.as_retriever()\n",
    "\n",
    "rag_prompt_template = \"\"\"\n",
    "Given a question and some context, answer the question.\n",
    "If you do not know the answer, just say I do not know.\n",
    "Answer in bullet points in Japanese.\n",
    "\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(rag_prompt_template)\n",
    "\n",
    "rewrite_retrieve_read_rag_chain = (\n",
    "    {\n",
    "        \"context\": {\"user_question\": RunnablePassthrough()}\n",
    "        | rewriter_chain\n",
    "        | retriever,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b549250-fcea-42f6-9792-b8aa0013f541",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = rewrite_retrieve_read_rag_chain.invoke(user_question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baa87f6",
   "metadata": {},
   "source": [
    "### çµæœ\n",
    "- ã¾ã ã¾ã æ”¹è‰¯ã®ä½™åœ°ãŒã‚ã‚‹ã€‚\n",
    "- è³ªå•ãŒã²ã©ã„å ´åˆã®å¯¾å¿œã‚’ã—ã¦ã„ã‚‹ã ã‘ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9313e5d3",
   "metadata": {},
   "source": [
    "## Multiple query generation ã‚’ä½¿ã£ã¦ã‚ˆã‚Šæ­£ç¢ºã«Vector DB ã‹ã‚‰Documentã‚’Retrieveã—ã‚ˆã†\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8700b4",
   "metadata": {},
   "source": [
    "### å¾“æ¥ã®RAGã®å•é¡Œç‚¹\n",
    "- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ã‚ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ã ã‘è¿‘ã„è¿‘ä¼¼å€¤ã‚¹ã‚³ã‚¢ã§Documentã‚’Retrieveã—ã¦ã—ã¾ã†ã€‚\n",
    "- ãã‚Œã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã®æ‰‹æ³•ãŒ Multiple query generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b87ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from typing import List\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3383dc63",
   "metadata": {},
   "source": [
    "### MultiQueryRetriver ã®å®Ÿè£…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34d85df",
   "metadata": {},
   "source": [
    "### Promptã®è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7a92b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_query_gen_prompt_template = \"\"\"\n",
    "You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines.\n",
    "Original question: {question}\n",
    "\"\"\"\n",
    "\n",
    "multi_query_gen_prompt = ChatPromptTemplate.from_template(\n",
    "    multi_query_gen_prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b889fa",
   "metadata": {},
   "source": [
    "### multi-query parser ã®è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a576578",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineListOutputParser(BaseOutputParser[List[str]]):\n",
    "    \"\"\"Parse out a question from each output line.\"\"\"\n",
    "\n",
    "    def parse(self, text: str) -> List[str]:\n",
    "        lines = text.strip().split(\"\\n\")\n",
    "        return list(filter(None, lines))\n",
    "\n",
    "\n",
    "questions_parser = LineListOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e9558f",
   "metadata": {},
   "source": [
    "### è³ªå•(Query)ã‚’è¤‡æ•°ä½œã‚‹ Chain ã®ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0b9f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_query_gen_chain = multi_query_gen_prompt | llm | questions_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feaad9b",
   "metadata": {},
   "source": [
    "### ã©ã®ã‚ˆã†ãªQueryãŒç”Ÿæˆã•ã‚Œã‚‹ã‹ã‚’ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de61b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_queries = multi_query_gen_chain.invoke(user_question)\n",
    "multiple_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1006f936",
   "metadata": {},
   "source": [
    "### MultiQueryRetrieverã‚’è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412015ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_retriever = granular_collection.as_retriever()\n",
    "\n",
    "multi_query_retriever = MultiQueryRetriever(\n",
    "    retriever=basic_retriever,\n",
    "    llm_chain=multi_query_gen_chain,\n",
    "    parser_key=\"lines\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77df0e75",
   "metadata": {},
   "source": [
    "### multi_query retrieverã®å‡ºåŠ›ã‚’ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372ba429",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = multi_query_retriever.invoke(user_question)\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c4fc60",
   "metadata": {},
   "source": [
    "# Step-back question ã®å®Ÿè£…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08485bd",
   "metadata": {},
   "source": [
    "### å¾“æ¥ã®RAGã®å•é¡Œç‚¹\n",
    "- è©³ç´°ãªè³ªå•ã‚’ã—ãŸã¨ãã«ã€ç‰¹å®šã®ã‚‚ã®ã‚’æ¤œç´¢ã—ã¦ã—ã¾ã†ã“ã¨ã«ã‚ˆã£ã¦ã€Retrieveã§ãã‚‹DocumentãŒæ¸›ã£ã¦ã—ã¾ã†ã€‚\n",
    "- ãã®ãŸã‚ã«ç”Ÿã¾ã‚ŒãŸæ‰‹æ³•ãŒ Step-back Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a210487",
   "metadata": {},
   "source": [
    "### Step-back question ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®æº–å‚™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46b8f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_back_prompt_template = \"\"\"\n",
    "Generate a less specific question (aka Step-back question) for the following detailed question, so that a wider context can be retrieved.\n",
    "Detailed question: {detailed_question}\n",
    "Step-back question:\n",
    "\"\"\"\n",
    "\n",
    "step_back_prompt = ChatPromptTemplate.from_template(step_back_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13243c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_back_question_gen_chain = step_back_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd513fcf",
   "metadata": {},
   "source": [
    "### step-back-question generation chain ã«ã‚ˆã£ã¦å¾—ã‚‰ã‚Œã‚‹è³ªå•ã‚’ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16db0f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_back_question = step_back_question_gen_chain.invoke(user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8fef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_back_question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce56f5eb",
   "metadata": {},
   "source": [
    "### Step-back question ã‚’RAG chain ã«å°å…¥ã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e576f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = granular_collection.as_retriever()\n",
    "\n",
    "rag_prompt_template = \"\"\"\n",
    "Given a question and some context, answer the question.\n",
    "If you do not know the answer, just say I do not know.\n",
    "If the information you get is in English, translate it to Japanese.\n",
    "You must answer in bullet points in Japanese.\n",
    "Give me as much detail as possible.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(rag_prompt_template)\n",
    "\n",
    "step_back_question_rag_chain = (\n",
    "    {\n",
    "        \"context\": {\"detailed_question\": RunnablePassthrough()}\n",
    "        | step_back_question_gen_chain\n",
    "        | retriever,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "user_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99265c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = step_back_question_rag_chain.invoke(user_question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e10cbe",
   "metadata": {},
   "source": [
    "##  Rewrite-Retrieve-Readã®åˆ©ç‚¹\n",
    "- ã–ã£ãã‚Šã®è³ªå•ã‹ã‚‰ã‚ˆã‚ŠVector DBãŒæ¤œç´¢ã—ã‚„ã™ã„ã€æ­£ç¢ºãªè¿‘ã—ã„Documentã‚’Retrieveã—ã¦ãã‚Œã‚‹ã‚ˆã†ãªè³ªå•ã«æ›¸ãæ›ãˆã¦ãã‚Œã‚‹\n",
    "\n",
    "## Multi Query Generationã®åˆ©ç‚¹\n",
    "- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è³ªå•ã‹ã‚‰è¤‡æ•°ã®è³ªå•ã‚’è‰²ã€…ãªè§’åº¦ã‹ã‚‰ç”Ÿæˆã—ã¦ãã‚‹ã“ã¨ã«ã‚ˆã‚Šã€è¿‘ä¼¼å€¤è¨ˆç®—ã®å¼Šå®³ã‚’å¼±ã‚ã¦ã‚ˆã‚Šè¿‘ã—ã„Documentã‚’Retrieveã™ã‚‹ã‚ˆã†ã«ã—ã¦ãã‚Œã‚‹\n",
    "## Step back Questionã®åˆ©ç‚¹\n",
    "- è©³ã—ã™ãã‚‹è³ªå•ã‚’ã—ãŸã¨ãã«ã€å¤šãã®Documentã‚’Retriveã—ã¦ãã‚Œã‚‹ã‚ˆã†ã«ã‚¹ã‚³ãƒ¼ãƒ—ã‚’åºƒã’ãŸè³ªå•ã«å¤‰æ›ã—ã¦ãã‚Œã‚‹\n",
    "\n",
    "## å•é¡Œç‚¹ã¯ï¼Ÿ\n",
    "- åŒã˜è³ªå•ã‚’ã—ã¦ã‚‚ã€ç­”ãˆã®è³ªãŒã°ã‚‰ã°ã‚‰ï¼ˆnon-deterministicï¼‰\n",
    "  - è§£æ±ºç­–ï¼š LoRAãªã©ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¿…è¦ \n",
    "- è³ªå•ã«ã‚ˆã£ã¦æ‰‹æ³•ã‚’å¤‰ãˆã‚‹å¿…è¦ãŒã‚ã‚‹\n",
    "  - è§£æ±ºç­–ï¼š LangGraphãªã©ã§æ¡ä»¶åˆ†å²ã‚’è¡Œã†å¿…è¦ãŒã‚ã‚‹ \n",
    "- ãã‚‚ãã‚‚ã€é–“é•ã£ãŸåœŸåœ°ã®æƒ…å ±ãŒå…¥ã£ã¦ã—ã¾ã†\n",
    "  - è§£æ±ºç­–ï¼š Chunkã®ãªã‹ã«ãƒ¡ã‚¿ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’åŸ‹ã‚è¾¼ã¿ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-study-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
